{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa58ff3",
   "metadata": {},
   "source": [
    "![img](https://python.langchain.com/v0.1/assets/images/data_connection-95ff2033a8faa5f3ba41376c0f6dd32a.jpg)  \n",
    "\n",
    "# 🧩 RAG 이전 단계: PDF 데이터 전처리 및 Vectorstore 구축 과정\n",
    "\n",
    "---\n",
    "\n",
    "## 📘 1️⃣ 개요\n",
    "\n",
    "RAG(Retrieval-Augmented Generation) 시스템은 **외부 지식 기반을 LLM에 연결**하여  \n",
    "보다 정확하고 근거 있는 답변을 생성하기 위한 구조입니다.\n",
    "\n",
    "이때 중요한 전처리 단계는 **PDF와 같은 문서 데이터를 LLM이 이해할 수 있는 벡터 형태로 변환하여 저장하는 과정**입니다.  \n",
    "이 과정이 잘 되어 있어야, 이후 RAG 단계에서 관련 문서를 빠르고 정확하게 검색할 수 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## ⚙️ 2️⃣ 전체 처리 흐름\n",
    "\n",
    "RAG를 위한 데이터 준비 과정은 다음 순서로 진행됩니다.\n",
    "\n",
    "1. **PDF 파일 로딩 (Loading)**  \n",
    "   문서 파일을 불러와 내부의 텍스트를 추출합니다.\n",
    "\n",
    "2. **텍스트 분할 (Text Splitting)**  \n",
    "   긴 문서를 LLM이 처리 가능한 단위로 나누어 문맥을 유지하면서 분할합니다.\n",
    "\n",
    "3. **임베딩 생성 (Embedding)**  \n",
    "   각 문서 조각을 의미적으로 표현할 수 있는 수치 벡터 형태로 변환합니다.\n",
    "\n",
    "4. **벡터스토어 저장 (Vectorstore Building)**  \n",
    "   생성된 벡터를 검색 가능한 데이터베이스 형태로 저장합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 3️⃣ 단계별 상세 설명\n",
    "\n",
    "### 🔹 1. PDF 로딩 (Loading)\n",
    "- PDF나 Word, HTML 등의 문서를 불러와 텍스트 데이터를 추출하는 단계입니다.  \n",
    "- 추출된 텍스트는 **Document 객체** 형태로 관리되며, 각 문서에는 본문 내용(`page_content`)과  \n",
    "  메타데이터(`metadata`, 예: 페이지 번호, 파일명 등)가 함께 저장됩니다.  \n",
    "- 이 단계는 “데이터를 LLM이 읽을 수 있는 형태로 변환하는 첫 번째 과정”입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 2. 텍스트 분할 (Text Splitting)\n",
    "- LLM은 한 번에 처리할 수 있는 텍스트 길이에 한계(토큰 제한)가 있습니다.  \n",
    "- 따라서 긴 문서를 일정 크기의 텍스트 조각으로 나누는 과정이 필요합니다.  \n",
    "- 분할 시, 문맥 손실을 최소화하기 위해 일부 겹치는 부분(Overlap)을 포함시킵니다.  \n",
    "- 이 단계의 목적은 “LLM이 각 문단을 이해할 수 있을 만큼의 크기 단위로 나누는 것”입니다.\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 3. 임베딩 생성 (Embedding)\n",
    "- 텍스트를 **의미적 벡터(Vector)** 로 변환하는 과정입니다.  \n",
    "- 임베딩 모델은 문장 또는 문서 조각을 다차원 수치 형태로 표현하여  \n",
    "  의미적으로 유사한 문장들이 서로 가까운 공간에 위치하도록 매핑합니다.  \n",
    "- 이 벡터화 과정을 통해 “텍스트의 의미를 수학적으로 표현”할 수 있습니다.  \n",
    "- 대표적인 임베딩 모델 예시: OpenAI Embeddings, Hugging Face Embeddings 등\n",
    "\n",
    "---\n",
    "\n",
    "### 🔹 4. 벡터스토어 구축 (Vectorstore Building)\n",
    "- 임베딩된 벡터를 **검색 가능한 형태로 저장**하는 단계입니다.  \n",
    "- 벡터스토어는 특정 질의(Query)의 벡터와 기존 문서 벡터들 간의  \n",
    "  **유사도(Similarity)** 를 계산하여 관련 문서를 빠르게 찾을 수 있도록 도와줍니다.  \n",
    "- 다양한 벡터 저장소 구현체가 존재하며, 상황에 맞게 선택할 수 있습니다.\n",
    "\n",
    "  **대표적인 Vectorstore 예시:**\n",
    "  - **FAISS**: 로컬 환경에서 빠른 벡터 검색을 지원하는 Meta의 오픈소스 엔진  \n",
    "  - **Chroma**: 간단한 로컬 개발 환경용 DB  \n",
    "  - **Pinecone / Weaviate / Milvus**: 클라우드 기반 대규모 벡터 데이터베이스  \n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 4️⃣ 결과 및 활용\n",
    "\n",
    "이 과정을 거치면, PDF의 비정형 텍스트 데이터가  \n",
    "**의미 기반 검색이 가능한 벡터 데이터베이스(Vectorstore)** 로 변환됩니다.\n",
    "\n",
    "| 단계 | 데이터 형태 | 역할 |\n",
    "|------|--------------|------|\n",
    "| 원본 PDF | 비정형 텍스트 | 사람이 읽을 수 있는 문서 |\n",
    "| 텍스트 분할 | 문맥 단위 조각 | 모델 입력 단위로 분할 |\n",
    "| 임베딩 | 다차원 벡터 | 문장 의미를 수치화 |\n",
    "| 벡터스토어 | 인덱스 구조 | 유사도 검색 및 RAG용 기반 데이터 |\n",
    "\n",
    "이후 RAG 시스템에서는 다음과 같은 순서로 동작합니다.\n",
    "\n",
    "1. 사용자의 질문을 임베딩 벡터로 변환  \n",
    "2. 벡터스토어에서 유사한 문서 벡터 검색  \n",
    "3. 검색된 문서 내용 + 질문을 함께 LLM에 전달  \n",
    "4. LLM이 문서 기반 답변을 생성  \n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 5️⃣ 정리\n",
    "\n",
    "| 단계 | 주요 목적 | 핵심 포인트 |\n",
    "|------|------------|--------------|\n",
    "| PDF 로딩 | 문서 텍스트 추출 | 비정형 데이터를 구조화 |\n",
    "| 텍스트 분할 | 문맥 단위로 나누기 | LLM의 토큰 제한 대응 |\n",
    "| 임베딩 생성 | 의미 기반 벡터화 | 유사 문장 간 거리 표현 |\n",
    "| 벡터스토어 구축 | 검색 가능 구조화 | RAG 시스템의 기반 데이터 구축 |  \n",
    "\n",
    "\n",
    "\n",
    "> 💡 **요약:**  \n",
    "> “RAG의 성능은 벡터스토어의 품질에 달려 있다.”  \n",
    "> 즉, 문서 전처리(분할, 임베딩, 저장) 과정이 정확할수록  \n",
    "> LLM이 생성하는 답변의 품질 또한 크게 향상됩니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13477231",
   "metadata": {},
   "source": [
    "### 📃 pdf loader\n",
    " - langchain 제공 PDF loader\n",
    " - 본 실습에서는 pymupdf를 사용 \n",
    "\n",
    "| 로더 | 내부 엔진 | 강점/용도 | 비고 |\n",
    "|---|---|---|---|\n",
    "| **PyPDFLoader** | `pypdf` | 텍스트 기반 PDF에 빠르고 가벼움. 페이지 단위 로딩, 동기/비동기 지원. | 설치: `pip install langchain-community pypdf`. |\n",
    "| **PyPDFium2Loader** | `pypdfium2` | 렌더링 기반 파서로 레이아웃 보존이 상대적으로 좋고, 대형 PDF에서 성능 이점 보고 사례 다수. 이미지 추출 옵션. | 설치: `pip install langchain-community pypdfium2`. |\n",
    "| **PyMuPDFLoader** | `PyMuPDF`(fitz) | 텍스트·이미지·표 추출 지원, 기능 풍부. 복잡한 레이아웃/스캔 혼합 문서에 견고. | 설치: `pip install langchain-community pymupdf`. |\n",
    "| **PDFPlumberLoader** | `pdfplumber` | 표(table) 추출에 강점. | 설치: `pip install langchain-community pdfplumber`. |\n",
    "| **PDFMinerLoader** | `pdfminer.six` | 세밀한 텍스트 추출·글자 단위 제어. 스캔 아닌 문서에 적합. | 설치: `pip install langchain-community pdfminer.six`. |\n",
    "| **UnstructuredPDFLoader** | `unstructured` | 제목/본문 등 **요소 단위 분해(elements)** 가능(“single”/“elements” 모드). 다종 포맷 혼합에 유리. | 설치: `pip install langchain-community unstructured`. |\n",
    "| **MathpixPDFLoader** | Mathpix OCR | 수식·스캔/이미지 PDF의 **OCR/수식 인식**에 특화. 출력 포맷 선택(`md` 등). | Mathpix API 키 필요. |\n",
    "| **OnlinePDFLoader** | HTTP(S)/S3 | **URL/S3 경로**에서 직접 다운받아 로드. | 헤더 지정 가능, 비동기 지원. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00a5d07a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/n-jison/Desktop/jaeig/kmu-agent-course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyMuPDFLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61b48528",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf'\n",
    "loader = PyMuPDFLoader(pdf_path)\n",
    "\n",
    "pdf_pages = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fe1c710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pdf_pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "939a359f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'producer': 'Hancom PDF 1.3.0.547',\n",
       " 'creator': 'Hwp 2022 12.0.0.3650',\n",
       " 'creationdate': '2025-03-24T15:26:49+09:00',\n",
       " 'source': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf',\n",
       " 'file_path': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf',\n",
       " 'total_pages': 30,\n",
       " 'format': 'PDF 1.6',\n",
       " 'title': '',\n",
       " 'author': '계명대학교 학사관리팀 팀장 김종학',\n",
       " 'subject': '',\n",
       " 'keywords': '',\n",
       " 'moddate': '2025-03-24T15:26:49+09:00',\n",
       " 'trapped': '',\n",
       " 'modDate': \"D:20250324152649+09'00'\",\n",
       " 'creationDate': \"D:20250324152649+09'00'\",\n",
       " 'page': 0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_pages[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cad07a02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'- 4 -\\n2. 2025학년도 학사일정표(홈페이지>대학생활>학사일정>학사세부일정)\\n     월   \\n요일\\n일\\n월\\n화\\n수\\n목\\n금\\n토\\n내용 및 일정\\n2025년 \\n3월\\n1\\n• 1학기 개시일: 1\\n• 대체공휴일(3·1절): 3\\n• 1학기 개강: 4\\n• 수강정정: 4 ~ 6\\n• 1학기 수업일수 ¼선: 31(27일차 30일 일요일)\\n2\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n4월\\n1\\n2\\n3\\n4\\n5\\n• 1학기 수업일수 ⅓선: 7(35일차)\\n• 고난 주간: 14 ~ 19\\n• 부활절: 20\\n• 부활절 예배: 24\\n• 1학기 수업일수 ½선: 25(53일차)\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n5월\\n1\\n2\\n3\\n• 근로자의날(휴업일): 1\\n• 부처님오신날 및 어린이날(공휴일): 5\\n• 교육실습: 5 ~ 30\\n• 대체공휴일(부처님오신날): 6\\n• 1학기 수업일수 ⅔선: 12(70일차)\\n• 창립기념일(휴업일): 20\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n6월\\n1\\n2\\n3\\n4\\n5\\n6\\n7\\n• 현충일(공휴일): 6\\n• 근로자의날[5. 1.(목)] 휴강에 대한 보강일: 10\\n• 부처님오신날 및 어린이날[5. 5.(월)] 휴강에 대한 보강일: 11\\n• 대체공휴일(부처님오신날)[5. 6.(화)] 휴강에 대한 보강일: 12\\n• 창립기념일(휴업일)[5. 20.(화)] 휴강에 대한 보강일: 13\\n• 현충일[6. 6.(금)] 휴강에 대한 보강일: 16\\n• 1학기 정기시험: 17 ~ 23\\n• 하계방학 및 계절학기 시작: 24\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n7월\\n1\\n2\\n3\\n4\\n5\\n• 2학기 재입학(1차) 신청: 1 ~ 11\\n• 2학기 재입학(2차) 신청: 21 ~ 25\\n• 2학기 복학 신청: 1 ~ 31\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31\\n8월\\n1\\n2\\n• 2학기 수강신청: 5 ~ 8\\n• 광복절(공휴일): 15\\n• 2024학년도 후기 학부 학위수여일: 21\\n• 2024학년도 후기 대학원 학위수여일: 21\\n• 2학기 등록금 수납: 22 ~ 27\\n• 2학기 개강예배: 27\\n3\\n4\\n5\\n6\\n7\\n8\\n9\\n10\\n11\\n12\\n13\\n14\\n15\\n16\\n17\\n18\\n19\\n20\\n21\\n22\\n23\\n24\\n25\\n26\\n27\\n28\\n29\\n30\\n31'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_pages[3].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0025f053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- 6 -\n",
      "3. 교육 과정\n",
      " - 대학에서 이수하여야 할 과목은 필수적으로 이수해야 하는 필수과목과 본인이 선택하여 이수하는 \n",
      "선택과목으로 구분하고 있으며, 영역별로는 교양과목(공통교양, 균형교양, 일반교양), 전공과목\n",
      "(전공필수, 전공선택, 전공인정), 교직과목으로 구분하고 있음(전공필수과목이 없는 학과도 있음)\n",
      "  가. 학점\n",
      "    1) 과목의 수업시간에 따른 기준임\n",
      "    2) 학점은 과목별로 정해져 있으며, 과목마다 일정한 성적이 되지 않으면 실격처리 되고,       \n",
      "실격된 과목은 이수학점으로 인정되지 않음\n",
      "구분\n",
      "내  용\n",
      "0학점\n",
      "채플, 졸업논문 등의 과목으로 학점은 없으나 필수과목의 경우 Pass(P학점)를 받아야 \n",
      "졸업할 수 있음\n",
      "1학점\n",
      "한 학기 동안 주당 1시간의 이론수업 또는 주당 2시간의 실험‧실습‧실기과목\n",
      "2학점\n",
      "한 학기 동안 주당 2시간의 이론수업 또는 주당 4시간의 실험‧실습‧실기과목\n",
      "단, 예‧체능계열의 경우 주당 3시간의 실기‧실습과목을 2학점으로 할 수도 있음\n",
      "3학점\n",
      "한 학기 동안 주당 3시간의 이론수업 또는 주당 6시간의 실험‧실습‧실기과목\n",
      "단, 예‧체능계열의 경우 주당 4시간의 실기‧실습과목을 3학점, 실용음악음향과는 \n",
      "주당 3시간(강의 2시간+실기 1시간)을 3학점으로 할 수도 있음\n",
      "   ※ 기타사항: 교육과정 운영에 따라 위의 학점 기준과 다른 교과목도 운영될 수 있음\n",
      "    3) 졸업학점과 이수허용학점\n",
      "      가) 입학연도별 졸업학점\n",
      "        (1) 2024학년도 입학생부터: 120학점\n",
      "          - 단, 사범대학 소속학과 및 간호학과 130학점 이상, 의학과 155학점 이상, 건축학과 165\n",
      "학점 이상, 약학과 및 제약학과는 216학점 이상\n",
      "        (2) 2023학년도 입학생까지: 130학점\n",
      "          - 단, 의학과 155학점 이상, 건축학과 165학점 이상, 약학과 및 제약학과는 216학점 이상\n",
      "      나) 입학연도별 이수허용학점\n",
      "        (1) 2024학년도 입학생부터: 학기당 18학점, 학년당 34학점을 초과하여 이수할 수 없음\n",
      "          - 단, 사범대학 소속 학과, 간호학과, 건축학과는 학기당 20학점, 학년당 36학점을 초과하\n",
      "여 이수할 수 없으며, 의학과, 약학부, 약학과, 제약학과는 학기당 24학점, 의예과는 학\n",
      "기당 21학점을 초과하여 이수할 수 없음\n",
      "        (2) 2023학년도 입학생까지: 학기당 20학점, 학년당 36학점을 초과하여 이수할 수 없음\n",
      "          - 단, 의학과, 약학과, 제약학과는 학기당 24학점, 의예과는 학기당 21학점을 초과하여 이\n",
      "수할 수 없음\n"
     ]
    }
   ],
   "source": [
    "test_text = pdf_pages[5].page_content\n",
    "print(test_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1a2d70",
   "metadata": {},
   "source": [
    "![img](https://python.langchain.com/assets/images/text_splitters-7961ccc13e05e2fd7f7f58048e082f47.png)\n",
    "### ✂️ TextSplitter\n",
    "문서를 특정기준으로 분할 할 때 활용<br>\n",
    "로드된 문서를 효율적으로 처리하고, 시스템이 정보를 보다 잘 활용할 수 있도록 준비하는 과정<br>  \n",
    "LLM이 받아들일 수 있는 효율적인 작은 규모의 조각으로 나누는 작업이며, 나중에 사용자가 입력한 질문에 대해 보다 효율적인 정보만 압축/선별하여 가져오기 위함<br>\n",
    "\n",
    "<h4> 분할의 필요성</h4>  \n",
    "<strong>핀포인트 정보 검색(정확성)</strong>   \n",
    "\n",
    "- 문서를 세분화함으로써 질문에 연관성이 있는 정보만 가져오는데 도움을 줌.\n",
    "- 각각의 단위는 특정 주제나 내용에 초점을 맞추므로, 관련성이 높은 정보를 제공 가능.\n",
    "\n",
    "<strong>리소스 최적화(효율성)</strong>  \n",
    "- 전체 문서를 LLM 으로 입력하게 되면 비용이 많이 발생\n",
    "-  효율적인 답변을 많은 정보속에 발췌하여 답변하지 못하고, 할루시네이션으로 이어짐.\n",
    "- 답변에 필요한 정보만 발췌하기 위한 목적도 있음\n",
    "\n",
    "<br>\n",
    "<hr>\n",
    "<h4>문서분할 과정</h4>  \n",
    "\n",
    "<strong>문서 구조 파악</strong>   \n",
    "\n",
    "- 다양한 형식의 문서 구조 파악, 문서의 헤더, 페이지 번호, 섹션 제목 등을 식별하는 과정을 포함\n",
    "\n",
    "<strong>단위 선정</strong>   \n",
    "\n",
    "- 문서를 어떤 단위로 나눌지 결정, 페이지별, 섹션별, 또는 문단별일 수 있으며, 문서의 내용과 목적에 따라 다름\n",
    "\n",
    "<strong>단위 선정 크기(Chunk Size)</strong>   \n",
    "\n",
    "- 문서를 몇 개의 토큰 단위로 나눌지 결정\n",
    "\n",
    "<strong>청크 오버랩(Chunk overlap)</strong>   \n",
    "\n",
    "- 분할된 끝 부분에서 맥락이 이어질 수 있도록 일부를 겹쳐(overlap) 분할하는 것이 일반적임\n",
    "\n",
    "Text Splitter 종류 : https://python.langchain.com/v0.2/api_reference/text_splitters/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "931410b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 6\n",
      "====== 0 ======\n",
      "====== 1 ======\n",
      "====== 2 ======\n",
      "====== 3 ======\n",
      "====== 4 ======\n",
      "====== 5 ======\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# \"\"\"\n",
    "# 일반적인 텍스트에 권장되는 방식\n",
    "# 문자 목록을 매개변수로 받아 동작하며, 청크가 충분히 작아질 때까지 주어진 문자 목록을 순서대로 텍스트 분할 시도\n",
    "# 기본 문자목록은 ['\\n\\n', '\\n', ' ', '']이며,\n",
    "# 단락 > 문장 > 단어 순서로 재귀적 분할함\n",
    "# \"\"\"\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=300, ## 청크의 최대 길이\n",
    "    chunk_overlap=100, ## 청크 간 중복되는 길이\n",
    "    length_function=len, ## 길이 측정 함수\n",
    "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"], ## 분할에 사용할 구분자 목록\n",
    "    keep_separator=True, ## 구분자를 청크에 포함할지 여부\n",
    "    is_separator_regex=False ## 구분자가 정규표현식인지 여부\n",
    ")   \n",
    "\n",
    "texts = text_splitter.split_text(test_text) ## 리스트 형태로 반환\n",
    "print(f\"Number of chunks: {len(texts)}\")\n",
    "\n",
    "for i, text in enumerate(texts):\n",
    "    print(f\"====== {i} ======\")\n",
    "    # print(text)\n",
    "# ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af56ded8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 0 has 34 chunks.\n",
      "--- Page 0 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 7 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 8 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 9 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 10 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 11 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 12 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 13 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 14 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 15 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 16 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 17 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 18 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 19 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 20 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 21 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 22 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 23 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 24 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 25 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 26 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 27 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 28 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 29 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 30 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 31 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 32 ---\n",
      "\n",
      "\n",
      "--- Page 0 - Chunk 33 ---\n",
      "\n",
      "\n",
      "Page 1 has 1 chunks.\n",
      "--- Page 1 - Chunk 0 ---\n",
      "\n",
      "\n",
      "Page 2 has 6 chunks.\n",
      "--- Page 2 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 2 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 2 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 2 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 2 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 2 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 3 has 7 chunks.\n",
      "--- Page 3 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 3 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 3 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 3 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 3 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 3 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 3 - Chunk 6 ---\n",
      "\n",
      "\n",
      "Page 4 has 6 chunks.\n",
      "--- Page 4 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 4 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 4 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 4 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 4 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 4 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 5 has 6 chunks.\n",
      "--- Page 5 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 5 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 5 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 5 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 5 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 5 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 6 has 6 chunks.\n",
      "--- Page 6 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 6 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 6 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 6 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 6 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 6 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 7 has 7 chunks.\n",
      "--- Page 7 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 7 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 7 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 7 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 7 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 7 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 7 - Chunk 6 ---\n",
      "\n",
      "\n",
      "Page 8 has 5 chunks.\n",
      "--- Page 8 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 8 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 8 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 8 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 8 - Chunk 4 ---\n",
      "\n",
      "\n",
      "Page 9 has 5 chunks.\n",
      "--- Page 9 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 9 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 9 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 9 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 9 - Chunk 4 ---\n",
      "\n",
      "\n",
      "Page 10 has 4 chunks.\n",
      "--- Page 10 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 10 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 10 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 10 - Chunk 3 ---\n",
      "\n",
      "\n",
      "Page 11 has 7 chunks.\n",
      "--- Page 11 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 11 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 11 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 11 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 11 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 11 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 11 - Chunk 6 ---\n",
      "\n",
      "\n",
      "Page 12 has 8 chunks.\n",
      "--- Page 12 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 12 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 12 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 12 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 12 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 12 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 12 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 12 - Chunk 7 ---\n",
      "\n",
      "\n",
      "Page 13 has 7 chunks.\n",
      "--- Page 13 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 13 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 13 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 13 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 13 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 13 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 13 - Chunk 6 ---\n",
      "\n",
      "\n",
      "Page 14 has 6 chunks.\n",
      "--- Page 14 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 14 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 14 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 14 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 14 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 14 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 15 has 9 chunks.\n",
      "--- Page 15 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 7 ---\n",
      "\n",
      "\n",
      "--- Page 15 - Chunk 8 ---\n",
      "\n",
      "\n",
      "Page 16 has 8 chunks.\n",
      "--- Page 16 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 16 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 16 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 16 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 16 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 16 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 16 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 16 - Chunk 7 ---\n",
      "\n",
      "\n",
      "Page 17 has 4 chunks.\n",
      "--- Page 17 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 17 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 17 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 17 - Chunk 3 ---\n",
      "\n",
      "\n",
      "Page 18 has 2 chunks.\n",
      "--- Page 18 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 18 - Chunk 1 ---\n",
      "\n",
      "\n",
      "Page 19 has 6 chunks.\n",
      "--- Page 19 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 19 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 19 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 19 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 19 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 19 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 20 has 8 chunks.\n",
      "--- Page 20 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 20 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 20 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 20 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 20 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 20 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 20 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 20 - Chunk 7 ---\n",
      "\n",
      "\n",
      "Page 21 has 8 chunks.\n",
      "--- Page 21 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 21 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 21 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 21 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 21 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 21 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 21 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 21 - Chunk 7 ---\n",
      "\n",
      "\n",
      "Page 22 has 12 chunks.\n",
      "--- Page 22 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 7 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 8 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 9 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 10 ---\n",
      "\n",
      "\n",
      "--- Page 22 - Chunk 11 ---\n",
      "\n",
      "\n",
      "Page 23 has 11 chunks.\n",
      "--- Page 23 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 6 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 7 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 8 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 9 ---\n",
      "\n",
      "\n",
      "--- Page 23 - Chunk 10 ---\n",
      "\n",
      "\n",
      "Page 24 has 7 chunks.\n",
      "--- Page 24 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 24 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 24 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 24 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 24 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 24 - Chunk 5 ---\n",
      "\n",
      "\n",
      "--- Page 24 - Chunk 6 ---\n",
      "\n",
      "\n",
      "Page 25 has 6 chunks.\n",
      "--- Page 25 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 25 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 25 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 25 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 25 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 25 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 26 has 6 chunks.\n",
      "--- Page 26 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 26 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 26 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 26 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 26 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 26 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 27 has 6 chunks.\n",
      "--- Page 27 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 27 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 27 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 27 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 27 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 27 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 28 has 6 chunks.\n",
      "--- Page 28 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 28 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 28 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 28 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 28 - Chunk 4 ---\n",
      "\n",
      "\n",
      "--- Page 28 - Chunk 5 ---\n",
      "\n",
      "\n",
      "Page 29 has 5 chunks.\n",
      "--- Page 29 - Chunk 0 ---\n",
      "\n",
      "\n",
      "--- Page 29 - Chunk 1 ---\n",
      "\n",
      "\n",
      "--- Page 29 - Chunk 2 ---\n",
      "\n",
      "\n",
      "--- Page 29 - Chunk 3 ---\n",
      "\n",
      "\n",
      "--- Page 29 - Chunk 4 ---\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Pdf 전체를 변환시켜보기\n",
    "\n",
    "for i in range(len(pdf_pages)):\n",
    "    pdf_page = pdf_pages[i] ## 각 페이지\n",
    "    pdf_text = pdf_page.page_content ## 각 페이지의 텍스트\n",
    "    pdf_metadata = pdf_page.metadata ## 각 페이지의 메타데이터\n",
    "    pdf_chunks = text_splitter.split_text(pdf_text) ## 각 페이지의 청크들\n",
    "    print(f\"Page {i} has {len(pdf_chunks)} chunks.\") \n",
    "\n",
    "    for j, chunk in enumerate(pdf_chunks): ## 각 페이지의 청크들 출력\n",
    "        print(f\"--- Page {i} - Chunk {j} ---\")  \n",
    "        # print(chunk) \n",
    "        print(\"\\n\")\n",
    "\n",
    "        # print(f\"Metadata for Page {i}:\")\n",
    "        # for key, value in pdf_metadata.items(): ## 메타데이터 출력\n",
    "        #     print(f\"  {key}: {value}\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e5417f",
   "metadata": {},
   "source": [
    "<img src='https://python.langchain.com/assets/images/embeddings_concept-975a9aaba52de05b457a1aeff9a7393a.png' width=600, height=400 />\n",
    "# 🧩 Embedding Models (임베딩 모델) — LangChain 개념 정리\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ 개요 및 역할\n",
    "\n",
    "- 임베딩 모델은 **텍스트를 고정 길이 벡터로 변환**하는 모델입니다.  \n",
    "- 이러한 벡터 표현은 텍스트의 **의미(semantic)** 를 수치화한 것입니다.  \n",
    "- 임베딩을 활용하면 단순 키워드 매칭을 넘어, **의미 기반 검색과 유사도 분석**이 가능합니다.  \n",
    "- 현재 LangChain은 주로 **텍스트 기반 임베딩**을 지원하며, 멀티모달 임베딩은 제한적으로만 제공됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ 핵심 개념\n",
    "\n",
    "### 🔹 텍스트 → 벡터 변환\n",
    "- 텍스트를 입력받아 **의미를 담은 수치 벡터**로 변환합니다.  \n",
    "- 같은 의미를 가진 문장은 벡터 공간에서 서로 **가까운 거리**로 표현됩니다.\n",
    "\n",
    "### 🔹 유사도 계산\n",
    "- 두 벡터 간의 거리를 계산하여 **의미적 유사성**을 판단합니다.  \n",
    "- 대표적인 거리 계산 방법:\n",
    "  - **코사인 유사도 (Cosine Similarity)**\n",
    "  - **유클리드 거리 (Euclidean Distance)**\n",
    "  - **내적 (Dot Product)**\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ LangChain의 공통 인터페이스\n",
    "\n",
    "LangChain은 여러 임베딩 모델 제공자(예: OpenAI, Hugging Face 등)를  \n",
    "**통합된 방식으로 제어할 수 있는 공통 인터페이스**를 제공합니다.\n",
    "\n",
    "- `embed_documents(texts: List[str])`  \n",
    "  여러 텍스트 문서를 한 번에 임베딩 벡터로 변환  \n",
    "- `embed_query(text: str)`  \n",
    "  단일 질의(예: 사용자의 질문)를 벡터로 변환  \n",
    "\n",
    "👉 일부 모델은 문서 임베딩과 질의 임베딩을 다르게 처리하므로,  \n",
    "두 메서드가 구분되어 있습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ 통합 제공자 (Integrations)\n",
    "\n",
    "LangChain은 다양한 임베딩 제공자와 연동할 수 있도록 설계되어 있습니다.  \n",
    "이를 통해 사용자는 **특정 벤더나 모델에 종속되지 않고**,  \n",
    "LangChain의 통합 추상화를 통해 일관된 방식으로 임베딩 기능을 사용할 수 있습니다.\n",
    "\n",
    "**대표적인 임베딩 모델 제공자 예시:**\n",
    "- OpenAI Embeddings  \n",
    "- Hugging Face Sentence Transformers  \n",
    "- Cohere Embeddings  \n",
    "- Vertex AI Text Embeddings  \n",
    "- Azure OpenAI Service  \n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ 벡터 공간과 유사도 의미\n",
    "\n",
    "- 임베딩된 텍스트는 **고차원 벡터 공간의 한 점(point)** 으로 표현됩니다.  \n",
    "- 의미적으로 유사한 텍스트는 이 공간에서 **서로 인접한 위치**에 놓입니다.  \n",
    "- 따라서 사용자의 질문(Query)을 임베딩하면,  \n",
    "  **가장 가까운 문서 벡터를 검색**하여 의미적으로 관련된 정보를 찾아낼 수 있습니다.\n",
    "\n",
    "> 💡 즉, “임베딩은 의미적 거리 기반 검색(Semantic Search)”의 핵심입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ 발전 흐름\n",
    "\n",
    "- 초기에는 BERT 등 일반 언어 모델이 문장 임베딩에 사용되었지만,  \n",
    "  문맥 유사도 측면에서는 최적화되지 않았습니다.  \n",
    "- 이후 **Sentence-BERT (SBERT)**, **E5**, **Instructor**, **text-embedding-3-large** 등의 모델이 등장하며  \n",
    "  문장 및 문서 수준의 임베딩 품질이 크게 향상되었습니다.  \n",
    "- 최근에는 MTEB 등 공개 벤치마크를 통해 모델 성능을 비교할 수 있게 되었습니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ 요약 및 주의점\n",
    "\n",
    "| 항목 | 설명 |\n",
    "|------|------|\n",
    "| **임베딩의 정의** | 텍스트를 의미 기반의 벡터로 변환 |\n",
    "| **활용 목적** | 검색, 분류, 유사도 비교, 추천 등 |\n",
    "| **LangChain 인터페이스** | `embed_documents()`, `embed_query()` |\n",
    "| **유사도 계산 방식** | 코사인 / 유클리드 / 내적 등 |\n",
    "| **성능 영향 요인** | 임베딩 모델 품질 + 전처리 품질 |\n",
    "| **한계점** | 모델 간 차이, 언어/도메인 편향 존재 |\n",
    "\n",
    "> 📌 **요약:**  \n",
    "> - 임베딩은 RAG, 검색, 추천 시스템의 핵심 기반입니다.  \n",
    "> - 벡터의 품질은 결과의 신뢰도에 직결되므로,  \n",
    ">   **도메인에 맞는 임베딩 모델 선택이 매우 중요합니다.**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f04d61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 1536\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\",\n",
    "                                    openai_api_key=OPENAI_API_KEY,\n",
    "                                    ) # OpenAI의 텍스트 임베딩 모델\n",
    "embeddings = embedding_model.embed_documents(pdf_chunks) ## 문서 임베딩 생성\n",
    "print(len(embeddings), len(embeddings[0])) ## 임베딩 벡터의 개수와 차원 수 출력\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c33b39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['- 30 -\\n경영대학 디지털경영학부 경영정보학과의 경우 졸업을 위해서 졸업논문 시험을 통과해야 합니다.\\n‘졸업논문’ 과목은 별도의 논문을 쓰는 것이 아니라 졸업논문 시험이며,\\n100점 만점에 60점 이상을 받아야 통과가 됩니다. \\n※ 4학년 1학기 혹은 2학기에 ‘졸업논문’ 과목을 개인이 직접 수강 신청을 하여야 합니다. \\n  (신청해야 졸업 가능)\\n졸업논문 시험은 주로 중간고사와 기말고사 사이에 있으며,\\n관련 일정은 학과 홈페이지에 공지합니다.',\n",
       " '(신청해야 졸업 가능)\\n졸업논문 시험은 주로 중간고사와 기말고사 사이에 있으며,\\n관련 일정은 학과 홈페이지에 공지합니다.\\n※ 경영정보학과 홈페이지(https://newcms.kmu.ac.kr/kmumis/index.do)\\n또한 시험을 대체할 수 있는 면제 기준이 있습니다.\\n아래의 면제 기준을 갖춘 학생은 면제 졸업논문 시험 면제신청서를 제출 기간에 맞춰\\n경영정보학과 사무실(의양관 120호)로 제출하면 졸업논문 시험이 면제됩니다. \\n※ 상황에 따라 변동 가능 (학과 홈페이지 참고)\\n졸업시험과목\\n졸업시험 면제 기준(택 1)\\n비고',\n",
       " '경영정보학과 사무실(의양관 120호)로 제출하면 졸업논문 시험이 면제됩니다. \\n※ 상황에 따라 변동 가능 (학과 홈페이지 참고)\\n졸업시험과목\\n졸업시험 면제 기준(택 1)\\n비고\\n경영정보학과\\n전공자격증\\n공인외국어능력시험\\n복수전공\\n경영정보학과 인정\\n전문자격증 및 기타 1급 \\n또는 2급 자격증\\n최근 2년 이내의 \\nCOMpass K 국제화영역\\n(외국어점수)\\n40포인트 이상\\n경영대학생이\\n경영대학 소속학과를\\n복수전공한 경우\\n졸업시험 면제 기준\\n(택 1) 포함\\n※ 전공 자격증 세부 명칭에 경우 아래의 표 참고\\n전문자격증',\n",
       " '(외국어점수)\\n40포인트 이상\\n경영대학생이\\n경영대학 소속학과를\\n복수전공한 경우\\n졸업시험 면제 기준\\n(택 1) 포함\\n※ 전공 자격증 세부 명칭에 경우 아래의 표 참고\\n전문자격증\\n정보처리기사, 정보처리산업기사, 국제공인자격증(ICDL 포함), MOS Master,\\n SCBP, SCAP, 데이터베이스개발자, 빅데이터분석기사, 데이터분석준전문가, \\n매경국가공인TEST(경제경영이해력시험) 600점이상\\n※ 2014학년도 신입생부터 모두 적용되는 사항이니 착오 없으시기를 바랍니다.',\n",
       " '매경국가공인TEST(경제경영이해력시험) 600점이상\\n※ 2014학년도 신입생부터 모두 적용되는 사항이니 착오 없으시기를 바랍니다. \\n  (편입생, 외국대학 복수학위 이수 학생, 외국인 학생 제외) \\n기타 문의는 경영정보학과 사무실(053-580-6428)로 문의 바람']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1e5e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1536\n"
     ]
    }
   ],
   "source": [
    "query = '아래의 면제 기준을 갖춘 학생은 면제 졸업논문 시험 면제신청서를 제출 기간에 맞춰\\n경영정보학과 사무실(의양관 120호)'\n",
    "query_embedding = embedding_model.embed_query(query) ## 쿼리 임베딩 생성\n",
    "print(len(query_embedding)) ## 쿼리 임베딩 벡터의 차원 수 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6db8556",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "청크와 질의간 유사도 0: 0.6377963824762751\n",
      "청크와 질의간 유사도 1: 0.6787469234801038\n",
      "청크와 질의간 유사도 2: 0.6707594658262833\n",
      "청크와 질의간 유사도 3: 0.5242897315537207\n",
      "청크와 질의간 유사도 4: 0.47744889883310104\n"
     ]
    }
   ],
   "source": [
    "## 유사도 계산하기\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "for i in range(len(embeddings)):\n",
    "    similarity = cosine_similarity(query_embedding, embeddings[i])\n",
    "    print(f\"청크와 질의간 유사도 {i}: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8de1b7",
   "metadata": {},
   "source": [
    "<img src=\"https://python.langchain.com/assets/images/vectorstores-2540b4bc355b966c99b0f02cfdddb273.png\" width=600 height=400/>\n",
    "\n",
    "# 🧠 Vector Store (벡터 저장소) 요약 자료\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ 개념 및 정의\n",
    "\n",
    "- **벡터 저장소(Vector Store, Vector Database)** 는 임베딩 벡터들을 효율적으로 저장하고 검색하기 위한 시스템 또는 데이터베이스입니다.  \n",
    "- 텍스트, 이미지, 오디오 등 다양한 데이터를 벡터 공간에 매핑한 뒤, 의미 기반 검색(semantic search)을 위해 사용됩니다.  \n",
    "- 주요 목적은 **대규모 벡터 데이터셋 속에서 가장 유사한 벡터 항목을 빠르게 찾아내는 것**입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 2️⃣ 벡터 저장소의 주요 기능\n",
    "\n",
    "| 기능 | 설명 |\n",
    "|---|------|\n",
    "| **벡터 저장 (Indexing / Storage)** | 고차원 벡터를 효율적으로 저장하고 색인(Index)을 구성 |\n",
    "| **벡터 검색 (Nearest Neighbor Search)** | 쿼리 벡터와 저장된 벡터 간의 거리/유사도 측정 후 유사 항목 탐색 |\n",
    "| **결과 반환 및 정렬** | 유사도 점수를 기준으로 가장 유사한 항목을 순서대로 제공 |\n",
    "| **확장성 / 대용량 처리** | 벡터가 많아져도 성능 저하 없이 관리 가능한 구조 제공 |\n",
    "| **메타데이터 연결** | 벡터뿐 아니라 문서 ID, 원문, 추가 속성(metadata)을 연결 관리 |\n",
    "\n",
    "---\n",
    "\n",
    "## 3️⃣ 유사도 측정 방식\n",
    "\n",
    "벡터 저장소에서는 쿼리 벡터와 저장 벡터 간의 유사도를 계산하여 검색을 수행합니다.  \n",
    "주요 거리/유사도 측정 방식은 다음과 같습니다:\n",
    "\n",
    "- **코사인 유사도 (Cosine Similarity)** — 방향성 기반 유사도  \n",
    "- **유클리드 거리 (Euclidean Distance)** — 벡터 공간 거리  \n",
    "- **내적 (Dot Product)** — 벡터의 내적 값이 클수록 유사\n",
    "\n",
    "텍스트 임베딩 기반 검색에서는 **코사인 유사도**가 자주 사용됩니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 4️⃣ 왜 벡터 저장소가 중요한가?\n",
    "\n",
    "벡터 저장소는 RAG 시스템이나 의미 기반 검색 시스템에서 핵심 역할을 합니다:\n",
    "\n",
    "- **빠른 검색 속도**  \n",
    " 임베딩 벡터를 색인화하고 최적화하여, 대규모 데이터 속에서도 유사도 기반 검색을 빠르게 수행할 수 있습니다.\n",
    "\n",
    "- **스케일러빌리티**  \n",
    " 데이터가 지속적으로 증가하더라도 시스템이 확장 가능해야 하며, 저장 구조가 성능 저하를 최소화해야 합니다.\n",
    "\n",
    "- **의미 기반 검색 지원**  \n",
    " 키워드 기반 검색이 갖는 한계를 넘어서, 의미적으로 유사한 문장을 찾아낼 수 있습니다.  \n",
    " 예: “모바일 디바이스 상에서 동작하는 인공지능 기술을 소개한 기업명은?” 같은 질의에 대해 문장 수준 의미 일치 문서를 탐색.\n",
    "\n",
    "- **검색 정확도 및 응답 품질에 직접적 영향**  \n",
    " 벡터 저장소의 품질(색인 전략, 거리 함수, 저장 방식 등)이 RAG 시스템의 응답 속도와 정확성에 큰 영향을 미칩니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 5️⃣ 벡터 저장소의 구성 요소 / 고려 요소\n",
    "\n",
    "- **색인 구조 및 방식**  \n",
    " 예: HNSW, IVF, PQ 등 다양한 근사 최근접이웃(Approximate Nearest Neighbor, ANN) 알고리즘  \n",
    "- **차원 감소 / 압축 기법**  \n",
    " 벡터 차원을 줄이거나 압축하여 저장 공간 절약 및 검색 속도 향상  \n",
    "- **배치 삽입 및 업데이트**  \n",
    " 새로운 벡터 삽입, 삭제, 업데이트 기능  \n",
    "- **메타데이터 관리**  \n",
    " 벡터와 연결된 문서 정보, 태그, ID 등을 저장하고 조회 가능하게 설계  \n",
    "- **성능 조정 및 튜닝**  \n",
    " 색인 파라미터 (예: 인덱스 크기, 탐색 깊이 등) 조정  \n",
    "- **내결함성 / 복제 / 분산 처리**  \n",
    " 클러스터 환경, 복제 구조, 장애 대응 설계\n",
    "\n",
    "---\n",
    "\n",
    "## 6️⃣ LangChain의 Vectorstores 개념\n",
    "\n",
    "LangChain에서는 벡터 저장소를 추상화된 방식으로 다룰 수 있도록 `VectorStore` 인터페이스를 제공합니다.\n",
    "\n",
    "- 벡터 저장소를 로컬 파일로 저장하거나 클라우드 벡터 DB(Pinecone, Weaviate 등)와 연동 가능  \n",
    "- 필요에 따라 거리 함수나 검색 파라미터를 설정할 수 있도록 유연한 API 제공\n",
    "\n",
    "LangChain 문서는 Vectorstores 개념을 다음과 같은 측면에서 강조합니다:\n",
    "\n",
    "- 벡터 저장소는 단순 저장소가 아니라 **검색 지능 계층** 역할을 한다  \n",
    "- 여러 벡터 DB 제공자를 벡터스토어 API 하나로 추상화하여, 백엔드 전환이 용이  \n",
    "- 검색 방식(예: 유사도 기반 검색)과 반환 방식(점수 포함 등)을 옵션으로 조절 가능  \n",
    "\n",
    "---\n",
    "\n",
    "## 7️⃣ 대표적인 벡터 저장소 / 구현체\n",
    "\n",
    "| 이름 | 특징 / 장점 | 사용 환경 |\n",
    "|------|--------------|------------|\n",
    "| **FAISS** | Facebook에서 개발한 고성능 벡터 검색 엔진 / 로컬 환경 최적화 | On-premise, 연구/프로토타입 |\n",
    "| **Chroma** | 파이썬 기반의 로컬 벡터 DB / 사용이 간편 | 개발, 테스트 환경 |\n",
    "| **Pinecone** | 클라우드 기반 벡터 DB / 자동 확장 및 관리 | 서비스 수준 RAG 시스템 |\n",
    "| **Milvus** | 분산형 벡터 DB / 대규모 벡터 데이터에 강점 | 엔터프라이즈 / 대규모 서비스 |\n",
    "\n",
    "---\n",
    "\n",
    "## 8️⃣ 요약\n",
    "\n",
    "- 벡터 저장소는 임베딩 벡터를 효율적으로 저장하고 검색할 수 있게 하는 핵심 구성 요소입니다.  \n",
    "- 의미 기반 검색(semantic search)을 가능하게 하며, RAG 시스템의 핵심 기반이 됩니다.  \n",
    "- 색인 구조, 유사도 함수, 메타데이터 관리, 성능 튜닝 등이 벡터스토어 선택과 설계에서 중요한 결정 요소입니다.  \n",
    "- LangChain은 다양한 백엔드 벡터 DB를 추상화된 API로 연동할 수 있게 하며, 검색과 저장을 일관된 방식으로 제어할 수 있게 해 줍니다.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "1528add3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kmu_llm']"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Milvus DB에 벡터 저장하기 \n",
    "import os \n",
    "from pymilvus import MilvusClient\n",
    "from langchain.vectorstores import Milvus\n",
    "\n",
    "db_dir = '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store'  # DB 디렉토리 경로\n",
    "db_name = 'kmu.db' # DB 파일 이름\n",
    "db_url = os.path.join(db_dir, db_name) # 전체 DB 경로\n",
    "\n",
    "client = MilvusClient(db_url) # Milvus 클라이언트 생성\n",
    "\n",
    "if client.has_collection('kmu_llm'): # 기존에 컬렉션이 존재하면 삭제\n",
    "    client.drop_collection('kmu_llm')\n",
    "client.create_collection( # 컬렉션 생성\n",
    "    collection_name='kmu_llm', # 컬렉션 이름\n",
    "    dimension=1536, # 임베딩 벡터의 차원 수\n",
    ")\n",
    "\n",
    "## 컬렉션이란 벡터와 관련된 데이터를 저장하는 논리적 단위\n",
    "## Milvus에서 컬렉션은 벡터 데이터와 메타데이터를 함께 저장\n",
    "## 각 컬렉션은 여러 필드로 구성될 수 있으며, 각 필드는 특정한 유형의 데이터를 저장\n",
    "## 예를 들어, 벡터 필드, 텍스트 필드, 메타데이터 필드 등이 있을 수 있음\n",
    "## 컬렉션을 생성할 때는 벡터의 차원 수, 인덱스 유형, 거리 함수 등 다양한 파라미터를 설정 가능\n",
    "\n",
    "client.list_collections() ## 컬렉션 목록 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "e802b34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data length: 5, 'data fields': dict_keys(['id', 'vector', 'text', 'meta'])\n",
      "vector dimensions : 1536\n"
     ]
    }
   ],
   "source": [
    "## Data preparation for Milvus\n",
    "data = [\n",
    "    {'id': i, 'vector': embeddings[i], 'text': pdf_chunks[i], 'meta': pdf_metadata}\n",
    "    for i in range(len(embeddings))\n",
    "]\n",
    "\n",
    "print(f\"data length: {len(data)}, 'data fields': {data[0].keys()}\")\n",
    "print(f'vector dimensions : {len(data[0][\"vector\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "aad0c557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserted 5 vectors into Milvus.\n"
     ]
    }
   ],
   "source": [
    "## insert data into Milvus\n",
    "res = client.insert(collection_name = 'kmu_llm', # 컬렉션 이름\n",
    "                    data = data) # 데이터 삽입\n",
    "\n",
    "print(f\"Inserted {res['insert_count']} vectors into Milvus.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "bcfc8827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query returned 5 results.\n",
      "=======\n",
      "0 - 30 -\n",
      "경영대학 디지털경영학부 경영정보학과의 경우 졸업을 위해서 졸업논문 시험을 통과해야 합니다.\n",
      "‘졸업논문’ 과목은 별도의 논문을 쓰는 것이 아니라 졸업논문 시험이며,\n",
      "10\n",
      "=======\n",
      "1 (신청해야 졸업 가능)\n",
      "졸업논문 시험은 주로 중간고사와 기말고사 사이에 있으며,\n",
      "관련 일정은 학과 홈페이지에 공지합니다.\n",
      "※ 경영정보학과 홈페이지(https://newcms.kmu\n",
      "=======\n",
      "2 경영정보학과 사무실(의양관 120호)로 제출하면 졸업논문 시험이 면제됩니다. \n",
      "※ 상황에 따라 변동 가능 (학과 홈페이지 참고)\n",
      "졸업시험과목\n",
      "졸업시험 면제 기준(택 1)\n",
      "비고\n",
      "경영\n",
      "=======\n",
      "3 (외국어점수)\n",
      "40포인트 이상\n",
      "경영대학생이\n",
      "경영대학 소속학과를\n",
      "복수전공한 경우\n",
      "졸업시험 면제 기준\n",
      "(택 1) 포함\n",
      "※ 전공 자격증 세부 명칭에 경우 아래의 표 참고\n",
      "전문자격증\n",
      "정보\n",
      "=======\n",
      "4 매경국가공인TEST(경제경영이해력시험) 600점이상\n",
      "※ 2014학년도 신입생부터 모두 적용되는 사항이니 착오 없으시기를 바랍니다. \n",
      "  (편입생, 외국대학 복수학위 이수 학생, 외\n"
     ]
    }
   ],
   "source": [
    "## 데이터가 잘 들어갔는지 확인하기 \n",
    "res = client.query(collection_name='kmu_llm', # 컬렉션 이름\n",
    "                   output_fields=['id', 'text', 'meta'], # 출력할 필드 목록\n",
    "                   filter=\"\",\n",
    "                   limit=5)\n",
    "\n",
    "print(f'Query returned {len(res)} results.')\n",
    "for i in res:\n",
    "    print('=======')\n",
    "    print(i['id'], i['text'][:100]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c1a1e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## langchain- Milvus 연동 >> document에서 바로 처리\n",
    "from langchain_milvus import Milvus\n",
    "\n",
    "connection_args = {\"uri\": db_url}  # ← 로컬 파일(DB) 경로\n",
    "index_params = {\"index_type\": \"FLAT\", \"metric_type\": \"L2\"}   # Lite에선 FLAT 사용 권장\n",
    "search_params = {\"metric_type\": \"L2\", \"params\": {\"nprobe\": 10}} # 검색 시 사용되는 파라미터 metric_tpye: 거리 측정 방식, params: 검색 시 사용되는 파라미터 nprobe: 검색 시 고려할 클러스터 수\n",
    "\n",
    "vector_store = Milvus.from_texts(texts = pdf_chunks,\n",
    "                    embedding = embedding_model,\n",
    "                    collection_name='langchain',\n",
    "                    metadatas = [pdf_metadata]*len(pdf_chunks),\n",
    "                    connection_args=connection_args,\n",
    "                    index_params=index_params,\n",
    "                    search_params=search_params,\n",
    "  )                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10de63b5",
   "metadata": {},
   "source": [
    "## Retriver\n",
    "\n",
    "저장된 벡터DB에서 사용자의 질문과 관련된 문서를 검색하는 과정\n",
    "이 단계에서 가장 적합한 정보를 신속하게 찾는 것이 목표  \n",
    "\n",
    "<h5><strong>검색기의 필요성</strong><h5>  \n",
    "<strong>정확한 정보 제공</strong>:   \n",
    "\n",
    "- 검색기는 사용자의 질문과 가장 관련성 높은 정보를 검색하여, 시스템이 정확하고 유용한 답변을 생성하도록 유도\n",
    "- 이 과정이 효과적으로 이루어지지 않으면, 결과적으로 제공되는 답변의 품질이 떨어짐\n",
    "\n",
    "<strong>응답 시간 단축</strong>:   \n",
    "\n",
    "- 효율적인 검색 알고리즘을 사용하여 데이터베이스에서 적절한 정보를 빠르게 검색함으로써, 전체적인 시스템 응답 시간을 단축시킴\n",
    "\n",
    "<strong>최적화</strong>:  \n",
    "- 효과적인 검색 과정을 통해 필요한 정보만을 추출함으로써 시스템 자원의 사용을 최적화하고, 불필요한 데이터 처리를 줄임.\n",
    "\n",
    "<h5><strong<동작 방식</strong><h5>\n",
    "\n",
    "- <strong>1. 질문의 벡터화</strong>:\n",
    "    - 사용자의 질문을 벡터 형태로 변환.\n",
    "    - 이 과정은 임베딩 단계와 유사한 기술을 사용하여 진행\n",
    "    - 변환된 질문 벡터는 후속 검색 작업의 기준점으로 사용.\n",
    "\n",
    "- <strong>2. 벡터 유사성 비교</strong>:\n",
    "    - 저장된 문서 벡터들과 질문 벡터 사이의 유사성을 계산\n",
    "    -  코사인 유사성(cosine similarity), Max Marginal Relevance(MMR) 등의 수학적 방법을 사용하여 수행.\n",
    "\n",
    "- <strong>3. 상위 문서 선정</strong>:\n",
    "    - 계산된 유사성 점수를 기준으로 상위 N개의 가장 관련성 높은 문서를 선정\n",
    "    -  문서들은 다음 단계에서 사용자의 질문에 대한 답변을 생성하는 데 사용\n",
    "\n",
    "- <strong>4. 문서 정보 반환</strong>:\n",
    "    - 선정된 문서들의 정보를 다음 단계(프롬프트 생성)로 전달\n",
    "    - 문서의 내용, 위치, 메타데이터 등 여러 정보가 포함됨\n",
    "\n",
    "<h5><strong>검색기의 중요성</strong></h5>\n",
    "\n",
    "- 검색기는 RAG 시스템에서 정보 검색의 질을 결정하는 핵심적인 역할을 수행.\n",
    "- 사용자 질문에 대한 적절한 컨텍스트를 제공하여, 언어 모델이 보다 정확한 답변을 생성할 수 있도록 도움\n",
    "> 검색기의 성능은 RAG 시스템의 전반적인 효율성과 사용자 만족도에 직접적인 영향을 미침."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "0de179d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result search returned 5 results.\n",
      "=======\n",
      "ID: 2, \n",
      "Text: 경영정보학과 사무실(의양관 120호)로 제출하면 졸업논문 시험이 면제됩니다. \n",
      "※ 상황에 따라 변동 가능 (학과 홈페이지 참고)\n",
      "졸업시험과목\n",
      "졸업시험 면제 기준(택 1)\n",
      "비고\n",
      "경영, \n",
      "Distance: 0.6578893661499023\n",
      "=======\n",
      "ID: 0, \n",
      "Text: - 30 -\n",
      "경영대학 디지털경영학부 경영정보학과의 경우 졸업을 위해서 졸업논문 시험을 통과해야 합니다.\n",
      "‘졸업논문’ 과목은 별도의 논문을 쓰는 것이 아니라 졸업논문 시험이며,\n",
      "10, \n",
      "Distance: 0.5678218603134155\n",
      "=======\n",
      "ID: 3, \n",
      "Text: (외국어점수)\n",
      "40포인트 이상\n",
      "경영대학생이\n",
      "경영대학 소속학과를\n",
      "복수전공한 경우\n",
      "졸업시험 면제 기준\n",
      "(택 1) 포함\n",
      "※ 전공 자격증 세부 명칭에 경우 아래의 표 참고\n",
      "전문자격증\n",
      "정보, \n",
      "Distance: 0.5302425622940063\n",
      "=======\n",
      "ID: 1, \n",
      "Text: (신청해야 졸업 가능)\n",
      "졸업논문 시험은 주로 중간고사와 기말고사 사이에 있으며,\n",
      "관련 일정은 학과 홈페이지에 공지합니다.\n",
      "※ 경영정보학과 홈페이지(https://newcms.kmu, \n",
      "Distance: 0.5044264793395996\n",
      "=======\n",
      "ID: 4, \n",
      "Text: 매경국가공인TEST(경제경영이해력시험) 600점이상\n",
      "※ 2014학년도 신입생부터 모두 적용되는 사항이니 착오 없으시기를 바랍니다. \n",
      "  (편입생, 외국대학 복수학위 이수 학생, 외, \n",
      "Distance: 0.4560106098651886\n"
     ]
    }
   ],
   "source": [
    "## vector search in Milvus\n",
    "query = \"경영정보학과 졸업논문 면제 기준\"\n",
    "query_embedding = embedding_model.embed_query(query) ## 쿼리 임베딩 생성\n",
    "res = client.search(collection_name='kmu_llm', # 컬렉션 이름\n",
    "                    data = [query_embedding], # 쿼리 임베딩\n",
    "                    limit=5, # 상위 k개 결과 반환\n",
    "                    output_fields=['id', 'text', 'meta'], # 출력할 필드 목록\n",
    ")\n",
    "\n",
    "for i in res:\n",
    "    print(f\"Result search returned {len(i)} results.\")\n",
    "    for j in i:\n",
    "        print('=======')\n",
    "        print(f\"ID: {j.id}, \\nText: {j.entity.get('text')[:100]}, \\nDistance: {j.distance}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "818c9604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result search returned 1 results.\n",
      "=======\n",
      "ID: 0, \n",
      "Text: - 30 -\n",
      "경영대학 디지털경영학부 경영정보학과의 경우 졸업을 위해서 졸업논문 시험을 통과해야 합니다.\n",
      "‘졸업논문’ 과목은 별도의 논문을 쓰는 것이 아니라 졸업논문 시험이며,\n",
      "10, \n",
      "Distance: 0.5680201053619385\n"
     ]
    }
   ],
   "source": [
    "## vector search in Milvus with filter\n",
    "## filter 조건을 사용하여 특정 메타데이터를 가진 벡터만 검색\n",
    "query = \"경영정보학과 졸업논문 면제 기준\"\n",
    "query_embedding = embedding_model.embed_query(query) ## 쿼리 임베딩 생성\n",
    "res = client.search(collection_name='kmu_llm', # 컬렉션 이름\n",
    "                    data = [query_embedding], # 쿼리 임베딩\n",
    "                    limit=5, # 상위 k개 결과 반환\n",
    "                    output_fields=['id', 'text', 'meta'], # 출력할 필드 목록\n",
    "                    filter=\"text like \\\"%디지털경영학부%\\\"\" # 필터 조건\n",
    ")\n",
    "\n",
    "\n",
    "for i in res:\n",
    "    print(f\"Result search returned {len(i)} results.\")\n",
    "    for j in i:\n",
    "        print('=======')\n",
    "        print(f\"ID: {j.id}, \\nText: {j.entity.get('text')[:100]}, \\nDistance: {j.distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "efb502bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search returned 3 results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'author': '계명대학교 학사관리팀 팀장 김종학', 'creationDate': \"D:20250324152649+09'00'\", 'creationdate': '2025-03-24T15:26:49+09:00', 'creator': 'Hwp 2022 12.0.0.3650', 'file_path': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': \"D:20250324152649+09'00'\", 'moddate': '2025-03-24T15:26:49+09:00', 'page': 29, 'pk': 461515625480323124, 'producer': 'Hancom PDF 1.3.0.547', 'source': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'subject': '', 'title': '', 'total_pages': 30, 'trapped': ''}, page_content='경영정보학과 사무실(의양관 120호)로 제출하면 졸업논문 시험이 면제됩니다. \\n※ 상황에 따라 변동 가능 (학과 홈페이지 참고)\\n졸업시험과목\\n졸업시험 면제 기준(택 1)\\n비고\\n경영정보학과\\n전공자격증\\n공인외국어능력시험\\n복수전공\\n경영정보학과 인정\\n전문자격증 및 기타 1급 \\n또는 2급 자격증\\n최근 2년 이내의 \\nCOMpass K 국제화영역\\n(외국어점수)\\n40포인트 이상\\n경영대학생이\\n경영대학 소속학과를\\n복수전공한 경우\\n졸업시험 면제 기준\\n(택 1) 포함\\n※ 전공 자격증 세부 명칭에 경우 아래의 표 참고\\n전문자격증'),\n",
       " Document(metadata={'author': '계명대학교 학사관리팀 팀장 김종학', 'creationDate': \"D:20250324152649+09'00'\", 'creationdate': '2025-03-24T15:26:49+09:00', 'creator': 'Hwp 2022 12.0.0.3650', 'file_path': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': \"D:20250324152649+09'00'\", 'moddate': '2025-03-24T15:26:49+09:00', 'page': 29, 'pk': 461515625480323122, 'producer': 'Hancom PDF 1.3.0.547', 'source': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'subject': '', 'title': '', 'total_pages': 30, 'trapped': ''}, page_content='- 30 -\\n경영대학 디지털경영학부 경영정보학과의 경우 졸업을 위해서 졸업논문 시험을 통과해야 합니다.\\n‘졸업논문’ 과목은 별도의 논문을 쓰는 것이 아니라 졸업논문 시험이며,\\n100점 만점에 60점 이상을 받아야 통과가 됩니다. \\n※ 4학년 1학기 혹은 2학기에 ‘졸업논문’ 과목을 개인이 직접 수강 신청을 하여야 합니다. \\n  (신청해야 졸업 가능)\\n졸업논문 시험은 주로 중간고사와 기말고사 사이에 있으며,\\n관련 일정은 학과 홈페이지에 공지합니다.'),\n",
       " Document(metadata={'author': '계명대학교 학사관리팀 팀장 김종학', 'creationDate': \"D:20250324152649+09'00'\", 'creationdate': '2025-03-24T15:26:49+09:00', 'creator': 'Hwp 2022 12.0.0.3650', 'file_path': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': \"D:20250324152649+09'00'\", 'moddate': '2025-03-24T15:26:49+09:00', 'page': 29, 'pk': 461515625480323125, 'producer': 'Hancom PDF 1.3.0.547', 'source': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'subject': '', 'title': '', 'total_pages': 30, 'trapped': ''}, page_content='(외국어점수)\\n40포인트 이상\\n경영대학생이\\n경영대학 소속학과를\\n복수전공한 경우\\n졸업시험 면제 기준\\n(택 1) 포함\\n※ 전공 자격증 세부 명칭에 경우 아래의 표 참고\\n전문자격증\\n정보처리기사, 정보처리산업기사, 국제공인자격증(ICDL 포함), MOS Master,\\n SCBP, SCAP, 데이터베이스개발자, 빅데이터분석기사, 데이터분석준전문가, \\n매경국가공인TEST(경제경영이해력시험) 600점이상\\n※ 2014학년도 신입생부터 모두 적용되는 사항이니 착오 없으시기를 바랍니다.')]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## langchain Milvus 유사도 검색\n",
    "query = \"경영정보학과 졸업논문 면제 기준\"\n",
    "res = vector_store.similarity_search(query = query,\n",
    "                                     k=3) ## 유사도 검색\n",
    "\n",
    "print(f'Similarity search returned {len(res)} results.')\n",
    "\n",
    "res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "1b048348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity search returned 1 results.\n",
      "=======\n",
      "- 30 -\n",
      "경영대학 디지털경영학부 경영정보학과의 경우 졸업을 위해서 졸업논문 시험을 통과해야 합니다.\n",
      "‘졸업논문’ 과목은 별도의 논문을 쓰는 것이 아니라 졸업논문 시험이며,\n",
      "100점 만점에 60점 이상을 받아야 통과가 됩니다. \n",
      "※ 4학년 1학기 혹은 2학기에 ‘졸업논문’ 과목을 개인이 직접 수강 신청을 하여야 합니다. \n",
      "  (신청해야 졸업 가능)\n",
      "졸업논문 시험은 주로 중간고사와 기말고사 사이에 있으며,\n",
      "관련 일정은 학과 홈페이지에 공지합니다.\n",
      "{'author': '계명대학교 학사관리팀 팀장 김종학', 'creationDate': \"D:20250324152649+09'00'\", 'creationdate': '2025-03-24T15:26:49+09:00', 'creator': 'Hwp 2022 12.0.0.3650', 'file_path': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'format': 'PDF 1.6', 'keywords': '', 'modDate': \"D:20250324152649+09'00'\", 'moddate': '2025-03-24T15:26:49+09:00', 'page': 29, 'pk': 461515625480323122, 'producer': 'Hancom PDF 1.3.0.547', 'source': '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/store/files/2025_mis_bluebook.pdf', 'subject': '', 'title': '', 'total_pages': 30, 'trapped': ''}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## langchain Milvus 유사도 검색 with filter\n",
    "query = \"경영정보학과 졸업논문 면제 기준\"\n",
    "res = vector_store.similarity_search(query = query,\n",
    "                                     expr = \"text like \\\"%디지털경영학부%\\\"\",\n",
    "                                     k=3) ## 유사도 검색\n",
    "\n",
    "print(f'Similarity search returned {len(res)} results.')\n",
    "for i in res:\n",
    "    print('=======')\n",
    "    print(i.page_content)\n",
    "    print(i.metadata)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "448ee30e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collection_name': 'langchain',\n",
       " 'auto_id': True,\n",
       " 'num_shards': 0,\n",
       " 'description': '',\n",
       " 'fields': [{'field_id': 100,\n",
       "   'name': 'text',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 101,\n",
       "   'name': 'pk',\n",
       "   'description': '',\n",
       "   'type': <DataType.INT64: 5>,\n",
       "   'params': {},\n",
       "   'auto_id': True,\n",
       "   'is_primary': True},\n",
       "  {'field_id': 102,\n",
       "   'name': 'vector',\n",
       "   'description': '',\n",
       "   'type': <DataType.FLOAT_VECTOR: 101>,\n",
       "   'params': {'dim': 1536}},\n",
       "  {'field_id': 103,\n",
       "   'name': 'producer',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 104,\n",
       "   'name': 'creator',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 105,\n",
       "   'name': 'creationdate',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 106,\n",
       "   'name': 'source',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 107,\n",
       "   'name': 'file_path',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 108,\n",
       "   'name': 'total_pages',\n",
       "   'description': '',\n",
       "   'type': <DataType.INT64: 5>,\n",
       "   'params': {}},\n",
       "  {'field_id': 109,\n",
       "   'name': 'format',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 110,\n",
       "   'name': 'title',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 111,\n",
       "   'name': 'author',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 112,\n",
       "   'name': 'subject',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 113,\n",
       "   'name': 'keywords',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 114,\n",
       "   'name': 'moddate',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 115,\n",
       "   'name': 'trapped',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 116,\n",
       "   'name': 'modDate',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 117,\n",
       "   'name': 'creationDate',\n",
       "   'description': '',\n",
       "   'type': <DataType.VARCHAR: 21>,\n",
       "   'params': {'max_length': 65535}},\n",
       "  {'field_id': 118,\n",
       "   'name': 'page',\n",
       "   'description': '',\n",
       "   'type': <DataType.INT64: 5>,\n",
       "   'params': {}}],\n",
       " 'functions': [],\n",
       " 'aliases': [],\n",
       " 'collection_id': 0,\n",
       " 'consistency_level': 0,\n",
       " 'properties': {},\n",
       " 'num_partitions': 0,\n",
       " 'enable_dynamic_field': False}"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.describe_collection(collection_name = 'langchain') ## 컬렉션 목록 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "281526e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'collection_name': 'kmu_llm',\n",
       " 'auto_id': False,\n",
       " 'num_shards': 0,\n",
       " 'description': '',\n",
       " 'fields': [{'field_id': 100,\n",
       "   'name': 'id',\n",
       "   'description': '',\n",
       "   'type': <DataType.INT64: 5>,\n",
       "   'params': {},\n",
       "   'is_primary': True},\n",
       "  {'field_id': 101,\n",
       "   'name': 'vector',\n",
       "   'description': '',\n",
       "   'type': <DataType.FLOAT_VECTOR: 101>,\n",
       "   'params': {'dim': 1536}}],\n",
       " 'functions': [],\n",
       " 'aliases': [],\n",
       " 'collection_id': 0,\n",
       " 'consistency_level': 0,\n",
       " 'properties': {},\n",
       " 'num_partitions': 0,\n",
       " 'enable_dynamic_field': True}"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.describe_collection(collection_name = 'kmu_llm') ## 컬렉션 목록 조회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21decf8b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
