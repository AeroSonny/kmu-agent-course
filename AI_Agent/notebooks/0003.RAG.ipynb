{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63bf42ce",
   "metadata": {},
   "source": [
    "## RAG êµ¬ì¶•\n",
    "# ğŸ“š RAG (Retrieval-Augmented Generation) ê°œë… ì •ë¦¬\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ RAGë€?\n",
    "\n",
    "- **RAG**ëŠ” **Retrieval-Augmented Generation**ì˜ ì•½ì–´ë¡œ, **ìƒì„±í˜• AI(LLM)**ì™€ **ì •ë³´ ê²€ìƒ‰(IR, ë²¡í„° ê²€ìƒ‰ ë“±)**ì„ ê²°í•©í•œ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.  [oai_citation:0â€¡LangChain](https://python.langchain.com/docs/concepts/rag/?utm_source=chatgpt.com)  \n",
    "- ì¼ë°˜ LLMì´ ë‚´ë¶€ í•™ìŠµëœ ê³ ì •ëœ ì§€ì‹ì—ë§Œ ì˜ì¡´í•˜ëŠ” ë°˜ë©´, RAGëŠ” **ì™¸ë¶€ ì§€ì‹ ì €ì¥ì†Œ(ë¬¸ì„œ, ë°ì´í„°ë² ì´ìŠ¤ ë“±)** ë¥¼ ì§ˆì˜ ì‹œì ì— ì°¸ì¡°í•˜ì—¬ ì‘ë‹µì„ ë³´ê°•í•©ë‹ˆë‹¤.  [oai_citation:1â€¡ìœ„í‚¤ë°±ê³¼](https://en.wikipedia.org/wiki/Retrieval-augmented_generation?utm_source=chatgpt.com)  \n",
    "- ì´ë¥¼ í†µí•´ LLMì´ ê°–ì§€ ëª»í•œ ìµœì‹  ì •ë³´, ë„ë©”ì¸ë³„ ë¬¸ì„œ ê¸°ë°˜ ì§€ì‹ ë“±ì„ í™œìš©í•  ìˆ˜ ìˆê²Œ í•˜ë©°, í™˜ê°(hallucination)ì„ ì¤„ì´ê³  ì‘ë‹µì˜ ì •í™•ì„±ê³¼ ì‹ ë¢°ì„±ì„ ë†’ì´ëŠ” íš¨ê³¼ê°€ ìˆìŠµë‹ˆë‹¤.  [oai_citation:2â€¡NVIDIA Blog](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/?utm_source=chatgpt.com)  \n",
    "\n",
    "---\n",
    "\n",
    "## 2ï¸âƒ£ RAGì˜ ê¸°ë³¸ êµ¬ì¡° / ì›Œí¬í”Œë¡œìš°\n",
    "\n",
    "RAG ì‹œìŠ¤í…œì€ ì¼ë°˜ì ìœ¼ë¡œ ë‹¤ìŒ 4ë‹¨ê³„ë¡œ êµ¬ì„±ë©ë‹ˆë‹¤:\n",
    "\n",
    "1. **ì¸ë±ì‹± / ìƒ‰ì¸í™”(Indexing)**  \n",
    "   ë¬¸ì„œë‚˜ ë°ì´í„° ì†ŒìŠ¤ë¥¼ ì „ì²˜ë¦¬í•˜ê³  ì„ë² ë”©(ë²¡í„°í™”)í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œ(vector database)ì— ì €ì¥í•©ë‹ˆë‹¤.  [oai_citation:3â€¡ìœ„í‚¤ë°±ê³¼](https://en.wikipedia.org/wiki/Retrieval-augmented_generation?utm_source=chatgpt.com)  \n",
    "\n",
    "2. **ë¦¬íŠ¸ë¦¬ë²Œ(Retrieval)**  \n",
    "   ì‚¬ìš©ìì˜ ì§ˆì˜(Query)ë¥¼ ì„ë² ë”©í•˜ì—¬, ë²¡í„° ì €ì¥ì†Œì—ì„œ ìœ ì‚¬ ë¬¸ì„œë“¤ì„ ê²€ìƒ‰í•©ë‹ˆë‹¤.  [oai_citation:4â€¡ìœ„í‚¤ë°±ê³¼](https://en.wikipedia.org/wiki/Retrieval-augmented_generation?utm_source=chatgpt.com)  \n",
    "\n",
    "3. **ì¦ê°•(Augmentation ë˜ëŠ” Context Injection)**  \n",
    "   ê²€ìƒ‰ëœ ë¬¸ì„œ(ë¬¸ë§¥)ë¥¼ ì§ˆì˜ì™€ í•¨ê»˜ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ì‹œì¼œ LLMì´ ì°¸ê³ í•  ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.  [oai_citation:5â€¡LangChain](https://python.langchain.com/docs/concepts/rag/?utm_source=chatgpt.com)  \n",
    "\n",
    "4. **ìƒì„±(Generation)**  \n",
    "   LLMì´ ì¦ê°•ëœ ì…ë ¥(ì§ˆì˜ + ë¬¸ë§¥)ì„ ë°”íƒ•ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.  [oai_citation:6â€¡LangChain](https://python.langchain.com/docs/concepts/rag/?utm_source=chatgpt.com)  \n",
    "\n",
    "> ì´ íë¦„ì€ â€œRetrieve â†’ Augment â†’ Generateâ€ ë˜ëŠ” â€œê²€ìƒ‰ â†’ ë³´ê°• â†’ ìƒì„±â€ íŒ¨í„´ìœ¼ë¡œ ê°„ë‹¨íˆ ìš”ì•½ë˜ê¸°ë„ í•©ë‹ˆë‹¤.  [oai_citation:7â€¡LangChain](https://python.langchain.com/docs/concepts/rag/?utm_source=chatgpt.com)  \n",
    "\n",
    "---\n",
    "\n",
    "## 3ï¸âƒ£ RAGì˜ ì¥ì  ë° í™œìš© íš¨ê³¼\n",
    "\n",
    "| ì¥ì  | ì„¤ëª… |\n",
    "|---|------|\n",
    "| **ìµœì‹  ì •ë³´ ë°˜ì˜ ê°€ëŠ¥** | ì™¸ë¶€ ì§€ì‹ ê¸°ë°˜ì„ ì°¸ì¡°í•¨ìœ¼ë¡œì¨, í•™ìŠµ ì´í›„ ìƒê¸´ ìµœì‹  ì‚¬ì‹¤ì´ë‚˜ ë„ë©”ì¸ ì§€ì‹ì„ í™œìš© ê°€ëŠ¥ |\n",
    "| **í™˜ê° ê°ì†Œ** | ì‘ë‹µ ì‹œ ë¬¸ë§¥ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒì„±í•˜ë¯€ë¡œ, LLMì´ ì•„ë¬´ ê·¼ê±° ì—†ì´ ë‹µì„ ë§Œë“œëŠ” ì˜¤ë¥˜ë¥¼ ì¤„ì¼ ìˆ˜ ìˆìŒ  [oai_citation:8â€¡NVIDIA Blog](https://blogs.nvidia.com/blog/what-is-retrieval-augmented-generation/?utm_source=chatgpt.com) |\n",
    "| **ë¹„ìš© íš¨ìœ¨ì„±** | ëª¨ë¸ì„ ìì£¼ ì¬í•™ìŠµí•  í•„ìš” ì—†ì´, ì™¸ë¶€ ì§€ì‹ ì €ì¥ì†Œë§Œ ì—…ë°ì´íŠ¸í•˜ë©´ ë¨  [oai_citation:9â€¡ìœ„í‚¤ë°±ê³¼](https://en.wikipedia.org/wiki/Retrieval-augmented_generation?utm_source=chatgpt.com) |\n",
    "| **ì¶œì²˜ ì œì‹œ ê°€ëŠ¥ì„±** | ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ì‘ë‹µê³¼ í•¨ê»˜ ì¸ìš©í•˜ê±°ë‚˜ ì°¸ì¡°í•˜ê²Œ í•˜ì—¬ ë‹µë³€ì˜ íˆ¬ëª…ì„±ê³¼ ê²€ì¦ ê°€ëŠ¥ì„±ì„ ì œê³µ |\n",
    "| **ë„ë©”ì¸ íŠ¹í™” ì‘ë‹µ** | ì¼ë°˜ì ì¸ LLMë³´ë‹¤ëŠ” íŠ¹ì • ë¬¸ì„œ ê¸°ë°˜ ì§€ì‹ì— ê°•í•œ ì‘ë‹µ ê°€ëŠ¥ |\n",
    "\n",
    "---\n",
    "\n",
    "## 4ï¸âƒ£ í•œê³„ ë° ë„ì „ ê³¼ì œ\n",
    "\n",
    "| í•œê³„ / ë¦¬ìŠ¤í¬ | ì„¤ëª… |\n",
    "|---|------|\n",
    "| **ì˜ëª»ëœ ë¬¸ì„œ ì„ ì • ê°€ëŠ¥ì„±** | ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì‹¤ì œ ì§ˆë¬¸ê³¼ ì–´ìš¸ë¦¬ì§€ ì•Šì„ ê²½ìš°, ë¶€ì ì ˆí•œ ë¬¸ë§¥ì´ í¬í•¨ë  ìˆ˜ ìˆìŒ |\n",
    "| **ë¬¸ë§¥ ê¸¸ì´ í•œê³„** | ë„ˆë¬´ ë§ì€ ë¬¸ì„œë¥¼ í¬í•¨í•˜ë©´ í”„ë¡¬í”„íŠ¸ ê¸¸ì´ ì œí•œ(token limit)ì— ê±¸ë¦´ ìˆ˜ ìˆê³ , í•µì‹¬ ë¬¸ë§¥ ì†ì‹¤ ìš°ë ¤ |\n",
    "| **ì‘ë‹µ ì˜¤ë¥˜ ì—¬ì „** | ë¬¸ë§¥ì´ ì •í™•í•´ë„ LLMì´ ì˜ëª» í•´ì„í•˜ê±°ë‚˜ ë²”ìœ„ ë°–ìœ¼ë¡œ ë²—ì–´ë‚œ ì‘ë‹µì„ ë§Œë“¤ ìˆ˜ ìˆìŒ |\n",
    "| **ê²€ìƒ‰ ë¹„ìš© / ì„±ëŠ¥ ë¶€ë‹´** | ëŒ€ê·œëª¨ ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ ìš´ì˜ ë¹„ìš©, ì¸ë±ìŠ¤ êµ¬ì¶• ë° ìœ ì§€ ë¹„ìš©ì´ ë°œìƒ |\n",
    "| **ë°ì´í„° ì¼ê´€ì„± / ë™ê¸°í™” ë¬¸ì œ** | ë¬¸ì„œê°€ ìì£¼ ë°”ë€” ê²½ìš° ì¸ë±ìŠ¤ ê°±ì‹  ë° ë²„ì „ ê´€ë¦¬ê°€ í•„ìš” |\n",
    "| **ë³´ì•ˆ / ì ‘ê·¼ í†µì œ ìœ„í—˜** | ë‚´ë¶€ ë¬¸ì„œë‚˜ ë¯¼ê° ë°ì´í„°ë¥¼ ì¤‘ì•™ ë²¡í„° ì €ì¥ì†Œì— ëª¨ì„ ê²½ìš° ë³´ì•ˆ ì´ìŠˆ ë°œìƒ ê°€ëŠ¥ |\n",
    "\n",
    "ë˜í•œ ì¼ë¶€ ê¸°ì—…ì—ì„œëŠ” **â€œRAGëŠ” êµ¬ì‹ì´ê³  ëŒ€ì‹  ì—ì´ì „íŠ¸ ê¸°ë°˜ AI êµ¬ì¡°ë¡œ ì „í™˜ ì¤‘â€**ì´ë¼ëŠ” ì£¼ì¥ë„ ë‚˜ì˜¤ê³  ìˆìŠµë‹ˆë‹¤.  [oai_citation:10â€¡TechRadar](https://www.techradar.com/pro/rag-is-dead-why-enterprises-are-shifting-to-agent-based-ai-architectures?utm_source=chatgpt.com)  \n",
    "\n",
    "---\n",
    "\n",
    "## 5ï¸âƒ£ RAG êµ¬í˜„ ì‹œ ê³ ë ¤ ìš”ì†Œ / íŒ\n",
    "\n",
    "- **ê²€ìƒ‰ ì •í™•ë„ ê°•í™”**  \n",
    "â€‚ë‹¨ìˆœ ë²¡í„° ê²€ìƒ‰ ì™¸ì— **í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰** (ë²¡í„° + í‚¤ì›Œë“œ ê¸°ë°˜ ê²€ìƒ‰ í˜¼í•©) ê¸°ë²• ì‚¬ìš©  \n",
    "â€‚ë˜í•œ ë¦¬ë­ì»¤(reranker)ë¥¼ ë‘ì–´ ê²€ìƒ‰ëœ ë¬¸ì„œ ìš°ì„ ìˆœìœ„ë¥¼ ì¬ì •ë ¬  \n",
    "\n",
    "- **Chunking ì „ëµ**  \n",
    "â€‚ë¬¸ì„œë¥¼ ì–´ë–»ê²Œ ë‚˜ëˆŒì§€ (ê³ ì • í¬ê¸° / ë¬¸ì¥ ê¸°ì¤€ / êµ¬ì¡° ê¸°ë°˜) ì„¤ê³„í•´ì•¼ ê²€ìƒ‰ í’ˆì§ˆì´ í–¥ìƒë¨  \n",
    "\n",
    "- **ì„ë² ë”© ëª¨ë¸ ì„ íƒ**  \n",
    "â€‚ë„ë©”ì¸ íŠ¹í™” ëª¨ë¸ì„ ì“°ê±°ë‚˜ ë¯¸ì„¸ ì¡°ì •í•œ ëª¨ë¸ì´ ë” ì¢‹ì€ ê²€ìƒ‰ í’ˆì§ˆì„ ì¤„ ìˆ˜ ìˆìŒ  \n",
    "\n",
    "- **ì»¨í…ìŠ¤íŠ¸ ê´€ë¦¬ / í”„ë¡¬í”„íŠ¸ ì„¤ê³„**  \n",
    "â€‚ë¬¸ë§¥ ê³¼ë¶€í•˜ë¥¼ ë°©ì§€í•˜ê³ , ì¤‘ìš” ë¬¸ë§¥ë§Œ ì œê³µí•˜ëŠ” ë°©ì‹ ì„¤ê³„  \n",
    "â€‚â€œì»¨í…ìŠ¤íŠ¸ ì™¸ ì‘ë‹µ ìì œâ€ ê·œì¹™, ìš”ì•½ + ì¸ìš© ë°©ì‹ ë³‘í–‰  \n",
    "\n",
    "- **ì¸ë±ìŠ¤ ë° ì €ì¥ì†Œ íŠœë‹**  \n",
    "â€‚ë²¡í„° ì €ì¥ì†Œ(ì˜ˆ: FAISS, Milvus ë“±)ì˜ ì¸ë±ìŠ¤ íŒŒë¼ë¯¸í„°, ê²€ìƒ‰ íŒŒë¼ë¯¸í„°(nprobe ë“±)ë¥¼ ìµœì í™”  \n",
    "\n",
    "- **ì‘ë‹µ ê²€ì¦ ë° í‰ê°€ ì§€í‘œ**  \n",
    "â€‚ì •í™•ë„, ì¬í˜„ìœ¨, F1, ì‘ë‹µ ì†ë„, ì‚¬ìš©ì ë§Œì¡±ë„ ë“±ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§  \n",
    "\n",
    "- **ì§€ì†ì  ì—…ë°ì´íŠ¸ ì „ëµ**  \n",
    "â€‚ìƒˆ ë¬¸ì„œ ì¶”ê°€, ì‚­ì œ, ìˆ˜ì •ì´ ìƒê¸¸ ë•Œ ì¸ë±ìŠ¤ ë™ê¸°í™” ë°©ì‹ ì„¤ê³„  \n",
    "\n",
    "---\n",
    "\n",
    "## 6ï¸âƒ£ LangChainì—ì„œì˜ RAG\n",
    "\n",
    "LangChainì€ RAGë¥¼ ì‰½ê²Œ êµ¬í˜„í•  ìˆ˜ ìˆë„ë¡ ì—¬ëŸ¬ ì¶”ìƒí™” ê³„ì¸µì„ ì œê³µí•©ë‹ˆë‹¤:  \n",
    "- **Vectorstores + Retrievers** ëª¨ë“ˆë¡œ ë¬¸ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ ì œê³µ  \n",
    "- **Chain / LCEL / Runnable** êµ¬ì„± ìš”ì†Œë¡œ ê²€ìƒ‰ ê²°ê³¼ + ì§ˆì˜ë¥¼ ì¡°í•©í•´ ì‘ë‹µ ìƒì„±  \n",
    "- **LangSmith**ë¡œ ê²€ìƒ‰ + ìƒì„± íë¦„ì„ ì¶”ì í•˜ê³  ëª¨ë‹ˆí„°ë§ ê°€ëŠ¥  [oai_citation:11â€¡LangChain](https://python.langchain.com/docs/tutorials/qa_chat_history/?utm_source=chatgpt.com)  \n",
    "- LangChain ê³µì‹ ë¬¸ì„œëŠ” RAG ê°œë…ì„ ì¤‘ì‹¬ìœ¼ë¡œ **Retrieval â†’ Augmentation â†’ Generation** íë¦„ì„ ì„¤ëª…í•©ë‹ˆë‹¤  [oai_citation:12â€¡LangChain](https://python.langchain.com/docs/concepts/rag/?utm_source=chatgpt.com)  \n",
    "\n",
    "---\n",
    "\n",
    "## 7ï¸âƒ£ ìµœê·¼ ì—°êµ¬ ë™í–¥ & ë°œì „\n",
    "\n",
    "- **Knowledge-Oriented RAG**: ì™¸ë¶€ ì§€ì‹ ê·¸ë˜í”„ë‚˜ êµ¬ì¡°í™”ëœ ì§€ì‹ì„ í™œìš©í•´ ê²€ìƒ‰ + ìƒì„±ì˜ ì •ë°€ì„±ì„ ë†’ì´ëŠ” ì—°êµ¬ê°€ ì§„í–‰ ì¤‘ì…ë‹ˆë‹¤.  [oai_citation:13â€¡arXiv](https://arxiv.org/abs/2503.10677?utm_source=chatgpt.com)  \n",
    "- **Prompt-RAG**: ë²¡í„° ì„ë² ë”© ì—†ì´ í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ ê²€ìƒ‰/ì¦ê°• ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ì—°êµ¬ (íŠ¹íˆ ë„ë©”ì¸ íŠ¹í™” ë¶„ì•¼)ë„ ì œì•ˆë¨  [oai_citation:14â€¡arXiv](https://arxiv.org/abs/2401.11246?utm_source=chatgpt.com)  \n",
    "- **OG-RAG (Ontology-Grounded RAG)**: ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ êµ¬ì¡°ì ìœ¼ë¡œ ì„ íƒ/ê²°í•©í•˜ëŠ” ë°©ì‹ ì œì•ˆë¨  [oai_citation:15â€¡arXiv](https://arxiv.org/abs/2412.15235?utm_source=chatgpt.com)  \n",
    "- RAG ë°©ë²•ë¡ ì„ **ì‚¬ì „ ê²€ìƒ‰ ë‹¨ê³„, í›„ì²˜ë¦¬ ë‹¨ê³„**ë¡œ ì„¸ë¶„í™”í•˜ê³  ì²´ê³„í™”í•œ ìµœê·¼ ë¦¬ë·° ë…¼ë¬¸ë“¤ë„ ë°œí‘œë˜ê³  ìˆìŠµë‹ˆë‹¤.  [oai_citation:16â€¡arXiv](https://arxiv.org/abs/2404.10981?utm_source=chatgpt.com)  \n",
    "\n",
    "---\n",
    "\n",
    "í•„ìš”í•˜ì‹œë©´ ì´ Markdownì„ êµìœ¡ìš© ìŠ¬ë¼ì´ë“œìš© ìš”ì•½ë³¸ìœ¼ë¡œ ì •ë¦¬í•´ë“œë¦´ê¹Œìš”? ë˜ëŠ” LangChain ê¸°ë°˜ ì‹¤ì „ RAG ì˜ˆì œ ì½”ë“œë„ ê°™ì´ ì •ë¦¬í•´ë“œë¦´ê¹Œìš”?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77485469",
   "metadata": {},
   "source": [
    "#### RAG (Retrieval Augmented Generation) - ì‹¤í–‰í•´ë³´ê¸°\n",
    "\n",
    "- 1. preprocessing (ë°ì´í„° ì „ì²˜ë¦¬) (ìˆ˜í–‰ì™„ë£Œ - milvusì— ë°ì´í„° ì ì¬ ì™„ë£Œ) -> kmu_llm ì»¬ë ‰ì…˜ì— ë°ì´í„° ì ì¬ë¨\n",
    "- 2. retrieval (ë°ì´í„° ê²€ìƒ‰) +  chatbot (ì±—ë´‡)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "58fbf46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/n-jison/Desktop/jaeig/kmu-agent-course/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    " ## í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ë° í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "# Milvus (pymilvus 2.4+)\n",
    "from pymilvus import MilvusClient\n",
    "from langchain.vectorstores import Milvus\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n",
    "\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53a5cbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/m4sc4mrs0md76r66w4tbnv_40000gn/T/ipykernel_25673/3396186098.py:7: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding_model = OpenAIEmbeddings(model = 'text-embedding-3-small',\n"
     ]
    }
   ],
   "source": [
    "## LLM ëª¨ë¸ ì„¤ì •\n",
    "llm = ChatOpenAI(model=\"gpt-4.1-nano\",\n",
    "                temperature=0.1, \n",
    "                openai_api_key=OPENAI_API_KEY)\n",
    "\n",
    "## ì„ë² ë”© ì„¤ì •\n",
    "embedding_model = OpenAIEmbeddings(model = 'text-embedding-3-small', \n",
    "                                openai_api_key = OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cec5cd19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to MilvusDB at /Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/retrieve/kmu.db, Collections: ['kmu_llm']\n",
      "Collection stats: {'row_count': 206}\n"
     ]
    }
   ],
   "source": [
    "## 1. MilvusDB ì—°ê²° ì„¤ì •\n",
    "db_dir = '/Users/n-jison/Desktop/jaeig/kmu-agent-course/AI_Agent/retrieve/'  # DB ë””ë ‰í† ë¦¬ ê²½ë¡œ\n",
    "db_name = 'kmu.db' # DB íŒŒì¼ ì´ë¦„\n",
    "db_url = os.path.join(db_dir, db_name) # ì „ì²´ DB ê²½ë¡œ\n",
    "client = MilvusClient(db_url) # Milvus í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "\n",
    "## ì—°ê²° í™•ì¸ \n",
    "stats = client.list_collections()\n",
    "if stats:  #\n",
    "    print(f\"Connected to MilvusDB at {db_url}, Collections: {stats}\")\n",
    "else:\n",
    "    print(f\"Failed to connect to MilvusDB at {db_url}\")\n",
    "\n",
    "## ë°ì´í„° ê°œìˆ˜ í™•ì¸\n",
    "stats = client.get_collection_stats(collection_name='kmu_llm')\n",
    "print(f\"Collection stats: {stats}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e91183aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 2. vectorDB ê²€ìƒ‰ & langchain êµ¬ì„± \n",
    "def question_embed(question:str) -> list:\n",
    "    return embedding_model.embed_query(question)\n",
    "    \n",
    "\n",
    "def rag_query(client: MilvusClient,\n",
    "              question: str,\n",
    "              top_k: int = 7) -> str:\n",
    "    # 1) ì§ˆë¬¸ ì„ë² ë”©\n",
    "    query_emb = embedding_model.embed_query(question)\n",
    "\n",
    "    # 2) ë²¡í„° ê²€ìƒ‰\n",
    "    res = client.search(\n",
    "        collection_name='kmu_llm',\n",
    "        data=[query_emb],                 # ìµœì‹  pymilvusì—ì„œëŠ” data ì‚¬ìš©\n",
    "        limit=top_k,\n",
    "        output_fields=['id', 'text', 'meta']\n",
    "    )\n",
    "    # print(f\"Search results: {res}\")\n",
    "    # 3) ì‹¤ì œ ë§¤ì¹˜ ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "    if not res or len(res[0]) == 0:\n",
    "        return \"ê´€ë ¨ ë¬¸ì„œê°€ ê²€ìƒ‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\"\n",
    "\n",
    "    # 4) ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´ êµ¬ì„± (ì¶œì²˜ í¬í•¨, ê¸¸ì´ ì œí•œ)\n",
    "    context_parts = []\n",
    "    for i, m in enumerate(res[0]):\n",
    "        # print(f\"ìœ ì‚¬ë„: {m.distance}\")\n",
    "        ent = m.entity\n",
    "        meta = ent.meta \n",
    "        text = ent.text\n",
    "\n",
    "        context_parts.append(f\"{i+1}. {text}\")\n",
    "\n",
    "    context = \"\\n\".join(context_parts)\n",
    "    # print(context)\n",
    "    return context, meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fceb701a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì§ˆë¬¸: ê²½ì˜ì •ë³´í•™ê³¼ëŠ” ì–´ë–¤ í•™ê³¼ì¸ê°€ìš”?\n",
      "ë‹µë³€: ('ê²½ì˜ì •ë³´í•™ê³¼ëŠ” ë¹„ì¦ˆë‹ˆìŠ¤ì™€ ì •ë³´ê¸°ìˆ ì´ ê²°í•©ëœ ë¶„ì•¼ë¡œ, ì„±ê³µì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ë¥¼ ìœ„í•´ í•„ìš”í•œ ì •ë³´ì™€ ì˜ì‚¬ê²°ì •ì˜ ì¤‘ìš”ì„±ì„ ì´í•´í•˜ê³  ì‹¤ë¬´ì— ì ìš©í•˜ëŠ” í•™ê³¼ì…ë‹ˆë‹¤. ì´ í•™ê³¼ì—ì„œëŠ” ê²½ì˜ì´ë¡ ê³¼ í•¨ê»˜ ë¹…ë°ì´í„°, í”„ë¡œê·¸ë˜ë°, ì†Œí”„íŠ¸ì›¨ì–´, ì •ë³´ì‹œìŠ¤í…œ ë“± ë‹¤ì–‘í•œ ê¸°ìˆ ê³¼ ê¸°ë²•ì„ ë°°ìš°ë©°, ì´ë¥¼ í†µí•´ ê²½ì˜ì— í•„ìš”í•œ í†µì°°ë ¥ì„ ê¸°ë¥´ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤. ì¦‰, ê²½ì˜ê³¼ ì •ë³´ê¸°ìˆ ì„ ìœµí•©í•˜ì—¬ ê¸°ì—…ì˜ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  í˜ì‹ ì„ ì´ë„ëŠ” ì „ë¬¸ê°€ë¥¼ ì–‘ì„±í•˜ëŠ” í•™ê³¼ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',)\n"
     ]
    }
   ],
   "source": [
    "## 3. ì±—ë´‡ êµ¬ì„±\n",
    "CHATBOT_PROMPT = \"\"\"\n",
    "## ì§€ì‹œì‚¬í•­\n",
    "ë‹¹ì‹ ì€ ì‚¬ìš©ìì—ê²Œ ë„ì›€ì„ ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. \n",
    "ì‚¬ìš©ìê°€ í•˜ëŠ” ì§ˆì˜ì— ëŒ€í•´, ê²€ìƒ‰ëœ ë¬¸ì„œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš” \n",
    "\n",
    "## ì œì•½ì‚¬í•­\n",
    "- ê²€ìƒ‰ëœ ë¬¸ì„œì˜ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”\n",
    "\n",
    "## ì…ë ¥\n",
    "- ì§ˆë¬¸: {question}\n",
    "- ê²€ìƒ‰ëœ ë¬¸ì„œ:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(CHATBOT_PROMPT)\n",
    "\n",
    "\n",
    "def chat_with_rag(llm,\n",
    "                prompt:ChatPromptTemplate,\n",
    "                question:str,\n",
    "                context:str) -> str:\n",
    "    chain = prompt | llm | StrOutputParser()\n",
    "    response = chain.invoke({'question': question, 'context': context})\n",
    "    # print(context)\n",
    "    return response\n",
    "\n",
    "## 4. RAG ì±—ë´‡ ì‹¤í–‰\n",
    "def rag_chatbot(client:MilvusClient,\n",
    "                llm,\n",
    "                prompt:ChatPromptTemplate,\n",
    "                question:str,\n",
    "                top_k:int=3) -> str:\n",
    "    context = rag_query(client, question, top_k)\n",
    "    answer = chat_with_rag(llm, prompt, question, context)\n",
    "    return answer, \n",
    "\n",
    "\n",
    "## ì˜ˆì‹œ ì§ˆì˜\n",
    "question = \"ê²½ì˜ì •ë³´í•™ê³¼ëŠ” ì–´ë–¤ í•™ê³¼ì¸ê°€ìš”?\"\n",
    "response = rag_chatbot(client, llm, prompt, question, top_k=5)\n",
    "\n",
    "print(\"ì§ˆë¬¸:\", question)\n",
    "print(\"ë‹µë³€:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df2a14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lecture2 (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
