# sLLM 파인튜닝 간결 가이드

> **대상**: 1B~13B급 small LLM(sLLM)  
> **목표**: 특정 도메인/태스크 성능 향상, 비용·지연(latency) 최소화

---

## 1) 파인튜닝이 필요한가요?
- **프롬프트 엔지니어링/리트리벌(RAG)** 만으로 해결 가능한지 먼저 검증하십시오.  
- 파인튜닝은 **데이터 준비 비용, 모델 편향 위험, 유지보수 부담**이 큽니다.  
- **지표**: 베이스+RAG 대비 품질 향상이 **명확히** 관측될 때만 착수하십시오.

---

## 2) 방법 선택
- **SFT (Supervised Fine-tuning)**: 정답이 있는 포맷(입력→출력). 가장 안전하고 기본적.  
- **DPO/Preference Tuning**: 선호 데이터(좋은/나쁜 응답 쌍)로 스타일·정렬 강화. 라벨 품질이 핵심.  
- **LoRA/QLoRA**: 저랭크 어댑터로 **메모리·시간 절약**. sLLM에서 **권장 기본 옵션**.  
- **어댑터/프롬프트 튜닝**: 파라미터 소량 업데이트. 경량 다중 태스크 운영에 적합.  
- **전면 미세조정(Full FT)**: 드뭅니다. **데이터·GPU·리스크**가 큼.

> 권장 기본: **QLoRA 기반 SFT → 필요시 DPO 추가**

---

## 3) 데이터
- **형식**: (시스템/지시문/입력/출력) 구조를 **일관**되게. JSONL 권장.  
- **규모 가이드(경험적)**: sLLM 7B 기준 **1만~20만** 고품질 예시 → 도메인 협소 시 더 적어도 효과.  
- **품질**: 중복 제거, 개인정보/저작권 필터링, 금지행동 제거.  
- **밸런스**: 유사 질문만 과다하면 **과적합/환각 증가**. 엣지 케이스 포함.  
- **평가 분리**: Train/Dev/Test **철저 분리**(리키지 방지).

---

## 4) 트레이닝 설정(권장 범위)
- **정밀도**: QLoRA(4bit nf4) + bf16 연산(가능 시).  
- **배치/스텝**: 유효 배치 64~256, 1~3 epoch(조기종료).  
- **러닝레이트**: 1e-5 ~ 2e-4 (SFT), 5e-7 ~ 5e-6 (DPO)에서 스윕.  
- **시퀀스 길이**: 실제 프롬프트 길이 분포를 반영(최대 길이 과도 증가는 비용↑).  
- **정규화**: weight decay 0.0~0.1, dropout/gradient clipping(1.0) 고려.  
- **모니터링**: loss만 보지 말고 **도메인 전용 Dev 세트 지표**를 주 지표로.

---

## 5) 평가
- **오프라인**: 정확도/ROUGE/BLEU/학습된 기준 + **휴리스틱 가드레일 테스트**.  
- **휴먼 평가**: 도메인 전문가 블라인드 A/B. 최소 수십~수백 케이스.  
- **안전성**: 금지 주제, PII, 환각, 추론 오류, 유해성 체크리스트 **자동화**.

---

## 6) 배포·운영
- **양자화**: 4/8bit로 RAM/VRAM 절감. 응답 지연이 큰 경우 **KV 캐시/서빙 엔진** 최적화.  
- **버전관리**: 데이터·하이퍼파라미터·체크포인트 해시로 **재현성** 확보.  
- **롤백 계획**: 성능 저하/유해 응답 발생 시 즉시 이전 버전으로 복귀.  
- **모델 드리프트**: 도메인 변화 감지 → **주기적 재평가/미세 업데이트**.

---

## 7) 흔한 함정(비판적 점검)
- **근거 없는 파인튜닝 남용**: RAG로 충분한데 모델을 바꿈 → 비용·위험만 증가.  
- **데이터 누출**: 테스트셋/실데이터가 학습에 섞임. 결과가 **허상**이 됩니다.  
- **지표 왜곡**: 손쉬운 예시 위주로 점수 상승. **실사용 시 품질 악화**.  
- **과도한 길이/문체 규제**: 과규제가 **창의성/일반화 저해**.  
- **저품질 선호 데이터**: DPO 시 **편향·유해성** 증폭. 큐레이션이 전부입니다.

---

## 8) 최소 구현 레시피(의사코드)
1. 데이터 준비(JSONL): `{"system": "...", "input": "...", "output": "..."}`  
2. 베이스 sLLM 로드 → **QLoRA 어댑터** 장착  
3. **SFT** 1~3 epoch 학습(Dev로 조기종료)  
4. 필요 시 **DPO**로 미세 조정(선호쌍 5k~50k)  
5. 4/8bit 양자화로 서빙 → 가드레일/모니터링 장착

---

## 체크리스트
- [ ] 베이스+RAG 대비 **명확한 개선 필요성** 확인  
- [ ] **데이터 품질·권리** 검증/로그 남김  
- [ ] Dev/Test **리키지 제로**  
- [ ] 오프라인 + 휴먼 평가 통과  
- [ ] 롤백/모니터링/드리프트 계획 수립

